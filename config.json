{   "task_config": {
        "lang": "es",
        "task": "binary",
        "prompt_type": "chain",
        "output_dir": "metaphor_LLM/zero_shot/interpretation/outputs"
    },
    "datasets": {
        "figurative-nli": {
            "data_path": "metaphorLLM/data/interpretation/Figurative-NLI/metaphor-entail.json",
            "data_path_paraphrase": "metaphorLLM/data/paraphrases/figurative-nli/commandr/15-10-2024_10_00_01.tsv",
            "prem_col": "premise",
            "hyp_col": "hypothesis",
            "label_col": "label",
            "prompts": ["binary", "paraphrase_gen"]
        },
        "flute": {
            "data_path": "metaphorLLM/data/interpretation/FLUTE/metaphor_test_binary_labels.tsv",
            "data_path_paraphrase": "metaphorLLM/data/paraphrases/flute/commandr/15-10-2024_10_03_13.tsv",
            "prem_col": "premise",
            "hyp_col": "hypothesis",
            "label_col": "label",
            "prompts": ["binary", "paraphrase_gen"]
        },
        "impli": {
            "data_path": "metaphorLLM/data/interpretation/IMPLI/manual_all.tsv",
            "data_path_paraphrase": "metaphorLLM/data/paraphrases/impli/commandr/15-11-2024_11_10_23.tsv",
            "prem_col": "premise",
            "hyp_col": "hypothesis",
            "label_col": "label",
            "prompts": ["binary", "paraphrase_gen"]
        },
        "fig-qa": {
            "data_path": "metaphorLLM/data/interpretation/Fig-QA/dev_binary_labels.tsv",
            "data_path_paraphrase": "metaphorLLM/data/paraphrases/fig-qa/commandr/15-10-2024_09_53_49.tsv",
            "prem_col": "premise",
            "hyp_col": "hypothesis",
            "label_col": "label",
            "prompts": ["binary", "paraphrase_gen"]
        },
        "meta4xnli": {
            "data_path": "metaphorLLM/data/interpretation/meta4xnli/test_met_binary_labels.tsv",
            "data_path_paraphrase": "metaphorLLM/data/paraphrases/meta4xnli/commandr/15-10-2024_10_13_19.tsv",
            "prem_col": "sentence1",
            "hyp_col": "sentence2",
            "label_col": "gold_label",
            "prompts": ["binary", "paraphrase_gen"]
        }
    },
    "models": {
        "llama3instruct": "meta-llama/Meta-Llama-3-8B-Instruct",
        "llama3-70b": "meta-llama/Meta-Llama-3-70B",
        "mistral7": "mistralai/Mistral-7B-v0.1",
        "commandr": "command-r-plus-08-2024",
        "qwen-7b": "Qwen/Qwen2.5-7B-Instruct",
        "qwen-72b": "Qwen/Qwen2.5-72B-Instruct",
        "gemma4": "google/gemma-3-4b-it",
        "gemma27": "google/gemma-3-27b-it"
    },
    "prompts": {
        "binary": {
            "nli-zero": {
                "preffix": "Say which is the inference relationship between these two sentences. Please, answer between 'entailment' or 'other'.",
                "label_mapping": {
                    "entailment": "entailment",
                    "other": "not_entailment"
                }
            },
            "nli-few": {
                "preffix": "Say which is the inference relationship between these two sentences. Please, answer between 'entailment' or 'other'. Here you have some examples: I am open -> I am friendly: entailment. My heart is broken -> I am happy: other.",
                "label_mapping": {
                    "entailment": "entailment",
                    "other": "not_entailment"
                }
            },
            "qa-zero-ent": {
                "preffix": "Are these two sentences entailed? Please, answer between 'yes' or 'no'",
                "label_mapping": {
                    "yes": "entailment",
                    "no": "not_entailment"
                }
            },
            "qa-few-ent": {
                "preffix": "Are these two sentences entailed? Please, answer between 'yes' or 'no'. Here you have some examples: I am open -> I am friendly: yes. My heart is broken -> I am happy: no.",
                "label_mapping": {
                    "yes": "entailment",
                    "no": "not_entailment"
                }
            },
            "chain": {
                "preffix": "You are an expert linguist and your task is to annotate sentences for the task of Natural Language Inference. This task consists in determining if a first sentence (premise) entails or not the second sentence (hypothesis). Please, limit your answer to 'yes' or 'no'. \n Here you have a few examples: \n Premise: I am an open person. \n Hypothesis: I am friendly. \n Answer: yes \n Premise: My heart is broken. \n Hypothesis: I am happy. \n Answer: no.",
                "label_mapping": {
                    "yes": "entailment",
                    "no": "not_entailment"
                }
            }
        },
        "paraphrase_gen": {
            "instruct": {
                "preffix": "Please, generate a literal paraphrase of this sentence. The sentence contains a metaphorical expression. Your task is to rewrite the sentence so it does not contain any metaphors. The generated sentence must have the same meaning as the original. Please, DO NOT include metaphorical or idiomatic expressions in the generated sentence. Answer only with the literal sentence. "
            }
        }
    }
}