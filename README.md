# metaphorLLM

This repository includes the data and code used in the paper **Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding.**

Our paper presents a comprehensive evaluation of the capabilities of Large Language Models (LLMs) in metaphor interpretation across multiple datasets, tasks, and prompt configurations. The results indicate that LLMs' performance is more influenced by features like lexical overlap and sentence length than by metaphorical content, demonstrating that any alleged emergent abilities of LLMs to understand metaphorical language are the result of a combination of surface-level features, in-context learning, and linguistic knowledge. This work provides critical insights into the current capabilities and limitations of LLMs in processing figurative language, highlighting the need for more realistic evaluation frameworks in metaphor interpretation tasks.

## DATA
For our evaluation, we used the following public datasets, gathered in `interpretation/`:
- Fig-QA: [Dataset](https://github.com/nightingal3/fig-qa)
- FLUTE: [Dataset](https://github.com/tuhinjubcse/model-in-the-loop-fig-lang)
- IMPLI: [Dataset](https://github.com/UKPLab/acl2022-impli)
- Figurative-NLI: [Dataset](https://github.com/tuhinjubcse/Figurative-NLI)
- Meta4XNLI: [Dataset](https://huggingface.co/datasets/HiTZ/meta4xnli)


## PARAPHRASES
`/paraphrases/*.tsv` files include paraphrases generated by `Commandr-R+` and `Mistral-7B-Instruct`.with premise, hypothesis gold label and the metaphorical paraphrased_sentence (can be either premise or hypothesis).
The structure is organized in the same manner as the `interpretation/` folder. 


